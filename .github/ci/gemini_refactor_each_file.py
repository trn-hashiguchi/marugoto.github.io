#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import base64
import json
import os
import re
import shlex
import subprocess
import sys
import time
from pathlib import Path
from typing import List, Tuple

from pathspec import PathSpec  # gitwildmatch

# ====== ç’°å¢ƒ ======
WORKSPACE = Path(os.getenv("GITHUB_WORKSPACE", ".")).resolve()
TARGET_BRANCH = os.getenv("TARGET_BRANCH", "develop")
MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-pro")
THRESHOLD = int(os.getenv("LLM_RATING_THRESHOLD", "3"))
MAX_PRS = int(os.getenv("LLM_MAX_PRS", "10"))
DRY_RUN = os.getenv("LLM_DRY_RUN", "false").lower() == "true"

INCLUDE_GLOBS = [g.strip() for g in os.getenv("LLM_INCLUDE_GLOBS", "").split(",") if g.strip()]
EXCLUDE_GLOBS = [g.strip() for g in (os.getenv("LLM_EXCLUDE_GLOBS") or "").split(",") if g.strip()]

# å®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé™¤å¤–ï¼ˆå‘¼ã³å‡ºã—å´ default ã¨ä¸€è‡´ï¼‰
DEFAULT_EXCLUDES = [
    "build/**","dist/**","vendor/**","vender/**","node_modules/**",".git/**",".github/**",
    "**/*.min.js","**/*.min.css","**/*.svg","**/*.png","**/*.jpg","**/*.jpeg","**/*.gif",
    "**/*.pdf","**/*.zip","**/*.gz","**/*.tgz","**/*.jar","**/*.lock",
    "**/package-lock.json","**/pnpm-lock.yaml","**/yarn.lock","**/package.json",
    "**/.DS_Store","**/__pycache__/**","coverage/**"
]

# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======
def run(cmd: str, check: bool = True, env: dict | None = None, cwd: Path | None = None) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, shell=True, text=True, capture_output=True, check=check, cwd=cwd, env=env)

def git(cmd: str, check: bool = True) -> subprocess.CompletedProcess:
    return run(f"git {cmd}", check=check)

def list_tracked_files() -> List[str]:
    res = git("ls-files")
    files = [ln for ln in res.stdout.splitlines() if ln.strip()]
    # include æŒ‡å®šãŒã‚ã‚Œã° include -> exclude é †ã«é©ç”¨
    inc_spec = PathSpec.from_lines("gitwildmatch", INCLUDE_GLOBS or ["**/*"])
    exc_spec = PathSpec.from_lines("gitwildmatch", (EXCLUDE_GLOBS or []) + DEFAULT_EXCLUDES)
    out = [f for f in files if inc_spec.match_file(f) and not exc_spec.match_file(f)]
    return out

def is_probably_text(path: Path) -> bool:
    try:
        b = path.read_bytes()[:8000]
        return b"\x00" not in b
    except Exception:
        return False

def sanitize_branch_component(s: str) -> str:
    s = re.sub(r"[^A-Za-z0-9._-]+", "-", s)[:60].strip("-")
    return s or str(int(time.time()))

def load_rules() -> str:
    p = WORKSPACE / "docs" / "rule.md"
    if not p.exists():
        return ""
    # éå¤§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå›é¿ï¼ˆ64KBï¼‰
    txt = p.read_text(encoding="utf-8", errors="ignore")
    if len(txt.encode("utf-8")) > 64 * 1024:
        txt = txt[:64 * 1024]
    return txt

# ====== LLM å‘¼ã³å‡ºã— ======
PROMPT_TEMPLATE = """ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚·ãƒ‹ã‚¢ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ä»¥ä¸‹ã®**å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«**ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¿…è¦ãªå ´åˆã®ã¿å®‰å…¨ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
**å‡ºåŠ›ã¯å¿…ãšJSONã®ã¿**ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹/èª¬æ˜æ–‡/å‰å¾Œãƒ†ã‚­ã‚¹ãƒˆç¦æ­¢ï¼‰ã€‚

å…¥åŠ›:
- file_path: {path}
- coding_rules (å­˜åœ¨ã—ãªã„å ´åˆã¯ã€Œãªã—ã€): <<RULES_START>>
{rules}
<<RULES_END>>
- file_content (UTF-8ãã®ã¾ã¾): <<FILE_START>>
{content}
<<FILE_END>>

åˆ¤å®šåŸºæº–ï¼ˆrefactor_level 1ã€œ5; 1=ä¸è¦, 2=è»½å¾®, 3=ä¸­ç¨‹åº¦, 4=æ˜ç¢ºãªæŠ€è¡“çš„è² å‚µ, 5=é‡å¤§ãªæ¬ é™¥/ãƒã‚°/ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ‡¸å¿µï¼‰ã€‚
**ç„¡ç†ã«ä¿®æ­£ç‚¹ã‚’æ¢ã•ãªã„**ã“ã¨ã€‚ã‚¹ã‚¿ã‚¤ãƒ«ã®ã¿/å¥½ã¿ã®å·®ã¯ 1ã€œ2 ã¨ã—ã€needs_refactor=false ã¨ã™ã‚‹ã€‚

JSONã‚¹ã‚­ãƒ¼ãƒ:
{{
  "file": "ç›¸å¯¾ãƒ‘ã‚¹",
  "refactor_level": 1|2|3|4|5,
  "reason": "æ—¥æœ¬èªã§ç°¡æ½”ã«ã€‚æ ¹æ‹ ãƒ»å½±éŸ¿ç¯„å›²ãƒ»ãƒªã‚¹ã‚¯",
  "needs_refactor": true|false,
  "new_content_b64": "needs_refactor=true ã®æ™‚ã®ã¿ã€‚UTF-8ã®æ–°ã‚½ãƒ¼ã‚¹ã‚’Base64åŒ–ã€‚falseãªã‚‰null"
}}

åˆ¶ç´„:
- æ©Ÿèƒ½ä»•æ§˜ã‚’å¤‰ãˆãªã„å®‰å…¨ãªæ”¹å–„ã«é™å®šã€‚
- JSONä»¥å¤–ã®å‡ºåŠ›ãƒ»diffã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢ã€‚
"""

def call_gemini_cli(prompt: str) -> str | None:
    # Vertex AI åˆ©ç”¨æ™‚ã¯ GEMINI_API_KEY ãŒç©ºã§ã‚ã‚‹ã“ã¨ã‚’æ¨å¥¨ï¼ˆç«¶åˆå›é¿ï¼‰
    env = os.environ.copy()
    env.pop("GEMINI_API_KEY", None)

    # éå¯¾è©±ãƒ¢ãƒ¼ãƒ‰: STDIN ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã™
    cmd = f"cat <<'EOF' | gemini -m {shlex.quote(MODEL)}\n{prompt}\nEOF"
    try:
        cp = run(cmd, check=True, env=env)
        out = cp.stdout.strip()
        # å ´åˆã«ã‚ˆã‚Šå‰å¾Œã«è£…é£¾ãŒä»˜ãå¯èƒ½æ€§ã‚’è€ƒæ…®ã—ã€æœ€åˆã® '{' ã€œ æœ€å¾Œã® '}' ã‚’æŠ½å‡º
        m = re.search(r"{.*}", out, flags=re.S)
        return m.group(0) if m else out
    except subprocess.CalledProcessError as e:
        sys.stderr.write(f"[gemini-cli] error: {e.stderr}\n")
        return None

def call_genai_sdk(prompt: str) -> str | None:
    # æ§‹é€ åŒ–å‡ºåŠ›: application/jsonï¼ˆSDKå´ã¯Vertex/ADCè¨­å®šã‚’ç¶™æ‰¿ï¼‰
    try:
        from google import genai
        from google.genai import types
        client = genai.Client(vertexai=True,
                              project=os.getenv("GOOGLE_CLOUD_PROJECT"),
                              location=os.getenv("GOOGLE_CLOUD_LOCATION", "global"))
        cfg = types.GenerateContentConfig(response_mime_type="application/json")
        resp = client.models.generate_content(model=MODEL, contents=prompt, config=cfg)
        return (resp.text or "").strip()
    except Exception as e:
        sys.stderr.write(f"[genai-sdk] fallback failed: {e}\n")
        return None

def review_one_file(path: Path, rules: str) -> dict | None:
    content = path.read_text(encoding="utf-8", errors="ignore")
    prompt = PROMPT_TEMPLATE.format(path=str(path), rules=(rules or "ãªã—"), content=content)

    raw = call_gemini_cli(prompt)
    if not raw or not raw.strip():
        raw = call_genai_sdk(prompt)

    # JSONãƒ‘ãƒ¼ã‚¹ï¼ˆç·©å’Œï¼šå…ˆé ­/æœ«å°¾ã®ãƒã‚¤ã‚ºã‚’é™¤å»ï¼‰
    if not raw:
        return None
    try:
        # æœ€ã‚‚å¤–å´ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¯„ã›ã‚‹
        m = re.search(r"{.*}", raw, flags=re.S)
        data = json.loads(m.group(0) if m else raw)
        return data
    except Exception as e:
        sys.stderr.write(f"[parse] JSON parse failed for {path}: {e}\nraw={raw[:300]}...\n")
        return None

# ====== PR ä½œæˆ ======
def ensure_on_branch(branch: str):
    run("git fetch origin --prune", check=True)
    run(f"git checkout {shlex.quote(branch)}", check=True)
    run(f"git pull --ff-only origin {shlex.quote(branch)}", check=True)

def create_branch(base_branch: str, for_file: Path) -> str:
    name = f"refactor/{sanitize_branch_component(for_file.as_posix())}-{int(time.time())}"
    run(f"git checkout -b {shlex.quote(name)} {shlex.quote(base_branch)}", check=True)
    return name

def commit_and_push(file_path: Path, level: int, reason: str, branch: str):
    run(f"git add -- {shlex.quote(file_path.as_posix())}", check=True)
    title = f"refactor: {file_path.as_posix()} (level {level}/5)"
    body = f"è‡ªå‹•ãƒªãƒ•ã‚¡ã‚¯ã‚¿ææ¡ˆ\n\n- refactor_level: **{level}/5**\n- reason: {reason}\n"
    run(f'git commit -m {shlex.quote(title)} -m {shlex.quote(body)}', check=True)
    run(f"git push -u origin {shlex.quote(branch)}", check=True)
    return title, body

def open_pr(base: str, head: str, title: str, body: str) -> Tuple[str, str]:
    env = os.environ.copy()
    token = env.get("GITHUB_TOKEN") or env.get("GH_TOKEN")
    if not token:
        raise RuntimeError("GITHUB_TOKEN/GH_TOKEN is not set")
    # PRä½œæˆ
    create_cmd = f"gh pr create -B {shlex.quote(base)} -H {shlex.quote(head)} --title {shlex.quote(title)} --body {shlex.quote(body)}"
    cp = run(create_cmd, check=True, env=env)
    url = (cp.stdout or "").strip().splitlines()[-1]
    # number å–å¾—
    num = run(f"gh pr view {shlex.quote(head)} --json number -q .number", check=True, env=env).stdout.strip()
    return num, url

def comment_to_pr(selector: str, level: int, reason: str):
    text = f"### ğŸ¤– ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒ¬ãƒ™ãƒ«: **{level}/5**\n\n**ç†ç”±**: {reason}\n"
    run(f"gh pr comment {shlex.quote(selector)} -b {shlex.quote(text)}", check=True)

# ====== ãƒ¡ã‚¤ãƒ³ ======
def main() -> int:
    ensure_on_branch(TARGET_BRANCH)
    files = [Path(f) for f in list_tracked_files()]
    files = [f for f in files if f.exists() and is_probably_text(f)]

    rules = load_rules()
    created = 0

    for f in files:
        if created >= MAX_PRS:
            print(f"[info] PR ä¸Šé™ {MAX_PRS} ä»¶ã«é”ã—ãŸãŸã‚æ‰“ã¡åˆ‡ã‚Šã€‚")
            break

        data = review_one_file(f, rules)
        if not data:
            print(f"[skip] LLMå¿œç­”ãªã—/JSONä¸æ­£: {f}")
            continue

        needs = bool(data.get("needs_refactor"))
        level = int(data.get("refactor_level") or 0)
        reason = str(data.get("reason") or "").strip()

        if not needs or level < THRESHOLD:
            print(f"[skip] {f} needs_refactor={needs} level={level} < {THRESHOLD}")
            continue

        b64 = data.get("new_content_b64")
        if not b64:
            print(f"[skip] {f} new_content_b64 ãŒç©º")
            continue

        new_src = base64.b64decode(b64).decode("utf-8", errors="ignore")

        # å¤‰æ›´ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        old_src = f.read_text(encoding="utf-8", errors="ignore")
        if new_src.strip() == old_src.strip():
            print(f"[skip] {f} å·®åˆ†ãªã—")
            continue

        if DRY_RUN:
            print(f"[dry-run] {f} level={level} reason={reason[:80]}...")
            continue

        # ãƒ–ãƒ©ãƒ³ãƒä½œã£ã¦ã‚³ãƒŸãƒƒãƒˆ & PR
        branch = create_branch(TARGET_BRANCH, f)
        f.write_text(new_src, encoding="utf-8")
        title, body = commit_and_push(f, level, reason, branch)
        pr_num, pr_url = open_pr(TARGET_BRANCH, branch, title, body)
        comment_to_pr(pr_num, level, reason)
        created += 1
        print(f"[created] PR #{pr_num} {pr_url} for {f}")

    if created == 0:
        print("[done] ä½œæˆPRãªã—ï¼ˆå…¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–¾å€¤æœªæº€/å·®åˆ†ãªã—/ä¸è¦åˆ¤å®šã§ã—ãŸï¼‰")

    return 0

if __name__ == "__main__":
    sys.exit(main())
